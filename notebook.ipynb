{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76a91c7d",
   "metadata": {},
   "source": [
    "### __What's Feature Engineering?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a20f4c",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "__Feature engineering__ is the process of turning raw data into useful features that help improve the performance of machine learning models. It includes choosing, creating and adjusting data attributes to make the model’s predictions more accurate. The goal is to make the model better by providing relevant and easy-to-understand information.\n",
    "\n",
    "A feature or attribute is a measurable property of data that is used as input for machine learning algorithms. Features can be _numerical_, _categorical_ or _text-based representing essential_ data aspects which are relevant to the problem.\n",
    "\n",
    "__Example:__ In housing price prediction, features might include the number of bedrooms, location and property age.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e1b901",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "![](./images/architecture.png)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1625eb0e",
   "metadata": {},
   "source": [
    "### __Importance of Feature Engineering__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9f6181",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "Feature engineering can significantly influence model performance. By refining features, we can:\n",
    "\n",
    "- __Improve accuracy__: Choosing the right features helps the model learn better, leading to more accurate predictions.\n",
    "\n",
    "- __Reduce overfitting__: Using fewer, more important features helps the model avoid memorizing the data and perform better on new data.\n",
    "\n",
    "- __Boost interpretability__: Well-chosen features make it easier to understand how the model makes its predictions.\n",
    "\n",
    "- __Enhance efficiency__: Focusing on key features speeds up the model’s training and prediction process, saving time and resources.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fdcd55",
   "metadata": {},
   "source": [
    "### __Processes Involved in Feature Engineering__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6544384",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "![](./images/involed_processes.png)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ee995e",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "1. __Feature Creation:__ Feature creation involves generating new features from domain knowledge or by observing patterns in the data. It can be:\n",
    "    - __Domain-specific:__ Created based on industry knowledge likr business rules.\n",
    "    - __Data-driven:__ Derived by recognizing patterns in data.\n",
    "    - __Synthetic:__ Formed by combining existing features.\n",
    "\n",
    "2. __Feature Transformation:__ Transformation adjusts features to improve model learning:\n",
    "    - __Normalization & Scaling:__ Adjust the range of features for consistency.\n",
    "    - __Encoding:__ Converts categorical data to numerical form i.e one-hot encoding.\n",
    "    - __Mathematical transformations:__ Like logarithmic transformations for skewed data.\n",
    "\n",
    "3. __Feature Extraction:__ Extracting meaningful features can reduce dimensionality and improve model accuracy:\n",
    "    - __Dimensionality reduction:__ Techniques like PCA reduce features while preserving important information.\n",
    "    - __Aggregation & Combination:__ Summing or averaging features to simplify the model.\n",
    "\n",
    "4. __Feature Selection:__ Feature selection involves choosing a subset of relevant features to use:\n",
    "    - __Filter methods:__ Based on statistical measures like correlation.\n",
    "    - __Wrapper methods:__ Select based on model performance.\n",
    "    - __Embedded methods:__ Feature selection integrated within model training.\n",
    "\n",
    "5. __Feature Scaling:__ Scaling ensures that all features contribute equally to the model:\n",
    "    - __Min-Max scaling:__ Rescales values to a fixed range like 0 to 1.\n",
    "    - __Standard scaling:__ Normalizes to have a mean of 0 and variance of 1.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9469639d",
   "metadata": {},
   "source": [
    "### __Steps in Feature Engineering__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3867b8",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "Feature engineering can vary depending on the specific problem but the general steps are:\n",
    "\n",
    "1. __Data Cleansing:__ Identify and correct errors or inconsistencies in the dataset to ensure data quality and reliability.\n",
    "2. __Data Transformation:__ Transform raw data into a format suitable for modeling including scaling, normalization and encoding.\n",
    "3. __Feature Extraction:__ Create new features by combining or deriving information from existing ones to provide more meaningful input to the model.\n",
    "4. __Feature Selection:__ Choose the most relevant features for the model using techniques like correlation analysis, mutual information and stepwise regression.\n",
    "5. __Feature Iteration:__ Continuously refine features based on model performance by adding, removing or modifying features for improvement.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc47bc42",
   "metadata": {},
   "source": [
    "### __Common Techniques in Feature Engineering__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3a1202",
   "metadata": {},
   "source": [
    "#### __1. One-Hot Encoding__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713774d6",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "__One-Hot Encoding__ converts categorical variables into binary indicators, allowing them to be used by machine learning models.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e07ef8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Color_Blue  Color_Green  Color_Red\n",
      "0       False        False       True\n",
      "1        True        False      False\n",
      "2       False         True      False\n",
      "3        True        False      False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = { 'Color': ['Red', 'Blue', 'Green', 'Blue']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df_encoded = pd.get_dummies(df, columns=['Color'], prefix='Color')\n",
    "\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5930ff5f",
   "metadata": {},
   "source": [
    "#### __2. Binning__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b075cb",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "__Binning__ transforms continuous variables into discrete bins, making them categorical for easier analysis.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef66f11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age Age_Binned\n",
      "0   23      21-40\n",
      "1   45      41-60\n",
      "2   18       0-20\n",
      "3   34      21-40\n",
      "4   67        61+\n",
      "5   50      41-60\n",
      "6   21      21-40\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'Age': [23, 45, 18, 34, 67, 50, 21]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "bins = [0, 20, 40, 60, 100]\n",
    "labels = ['0-20', '21-40', '41-60', '61+']\n",
    "\n",
    "df['Age_Binned'] = pd.cut(df['Age'], bins=bins, labels=labels)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35094a97",
   "metadata": {},
   "source": [
    "#### __3. Text Data Preprocessing__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314725fa",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "Involves removing stop-words, stemming and vectorizing text data to prepare it for machine learning models.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "552b837d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Texts: ['sampl sentence.', 'text data preprocess important.']\n",
      "Vectorized Text: [[0 0 0 1 1 0]\n",
      " [1 1 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texts = [\"This is a sample sentence.\", \"Text data preprocessing is important.\"]\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    words = text.split()\n",
    "    words = [stemmer.stem(word)\n",
    "             for word in words if word.lower() not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "cleaned_texts = [preprocess_text(text) for text in texts]\n",
    "\n",
    "X = vectorizer.fit_transform(cleaned_texts)\n",
    "\n",
    "print(\"Cleaned Texts:\", cleaned_texts)\n",
    "print(\"Vectorized Text:\", X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7caca6a",
   "metadata": {},
   "source": [
    "#### __4. Feature Splitting__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3700234b",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "Divides a single feature into multiple sub-features, uncovering valuable insights and improving model performance.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c2bbd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Full_Address      Street         City Zipcode\n",
      "0  123 Elm St, Springfield, 12345  123 Elm St  Springfield   12345\n",
      "1  456 Oak Rd, Shelbyville, 67890  456 Oak Rd  Shelbyville   67890\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Full_Address': [\n",
    "        '123 Elm St, Springfield, 12345',\n",
    "        '456 Oak Rd, Shelbyville, 67890'\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df[['Street', 'City', 'Zipcode']] = df['Full_Address'].str.extract(\n",
    "    r'([0-9]+\\s[\\w\\s]+),\\s([\\w\\s]+),\\s(\\d+)')\n",
    "\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow_env)",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
