{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dde3268b",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "Feature Scaling is a technique to standardize the independent features present in the data. It is performed during the data pre-processing to handle highly varying values. If feature scaling is not done then __machine learning algorithm tends to use greater values as higher and consider smaller values as loIr regardless of the unit of the values__. For example it will take 10 m and 10 cm both as same regardless of their unit. In this article I will learn about different techniques which are used to perform feature scaling.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca84c13c",
   "metadata": {},
   "source": [
    "### __1. Absolute Maximum Scaling__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cbbb94",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "This method of scaling requires two-step:\n",
    "\n",
    "1. I should first select the maximum absolute value out of all the entries of a particular measure.\n",
    "2. Then after this I divide each entry of the column by this maximum value.\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![](../images/absolute-maximum-scaling.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "After performing the above-mentioned two steps I will observe that each entry of the column lies in the range of -1 to 1. But this method is not used that often the reason behind this is that it is too sensitive to the outliers. And while dealing with the real-world data presence of outliers is a very common thing. \n",
    "\n",
    "For the demonstration purpose I will use the __SampleFile dataset__ which store in dataset folders as `SampleFile.csv`. This dataset is a simpler version of the original house price prediction dataset having only two columns from the original dataset. The first five rows of the original data are shown below:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b5a80a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LotArea  MSSubClass\n",
      "0     8450          60\n",
      "1     9600          20\n",
      "2    11250          60\n",
      "3     9550          70\n",
      "4    14260          60\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../datasets/SampleFile.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b77649",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "Now let's apply the first method which is of the absolute maximum scaling. For this first, I are supposed to evaluate the absolute maximum values of the columns.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "291f401b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LotArea       215245\n",
       "MSSubClass       190\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "max_vals = np.max(np.abs(df), axis=0)\n",
    "max_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954ec910",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "Now we are supposed to subtract these values from the data and then divide the results from the maximum values as well. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "151507b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       LotArea  MSSubClass\n",
      "0    -0.960742   -0.684211\n",
      "1    -0.955400   -0.894737\n",
      "2    -0.947734   -0.684211\n",
      "3    -0.955632   -0.631579\n",
      "4    -0.933750   -0.684211\n",
      "...        ...         ...\n",
      "1455 -0.963219   -0.684211\n",
      "1456 -0.938791   -0.894737\n",
      "1457 -0.957992   -0.631579\n",
      "1458 -0.954856   -0.894737\n",
      "1459 -0.953834   -0.894737\n",
      "\n",
      "[1460 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print((df - max_vals) / max_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26e7068",
   "metadata": {},
   "source": [
    "### __2. Min-Max Scaling__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c275a90d",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "This method of scaling requires below two-step:\n",
    "\n",
    "1. First we are supposed to find the minimum and the maximum value of the column.\n",
    "2. Then we will subtract the minimum value from the entry and divide the result by the difference between the maximum and the minimum value.\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![](../images/min-max-scaling.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "As we are using the maximum and the minimum value this method is also prone to outliers but the range in which the data will range after performing the above two steps is between 0 to 1.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e84a07ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>MSSubClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033420</td>\n",
       "      <td>0.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.038795</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.046507</td>\n",
       "      <td>0.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.038561</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060576</td>\n",
       "      <td>0.235294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LotArea  MSSubClass\n",
       "0  0.033420    0.235294\n",
       "1  0.038795    0.000000\n",
       "2  0.046507    0.235294\n",
       "3  0.038561    0.294118\n",
       "4  0.060576    0.235294"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1c0f1b",
   "metadata": {},
   "source": [
    "### __3. Normalization__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f49e46c",
   "metadata": {},
   "source": [
    "<div align=\"justify\">\n",
    "\n",
    "Normalization is the process of adjusting the values of data points so that they all have the same length or size, specifically a length of 1. This is done by dividing each data point by the \"length\" (called as Euclidean norm) of that data point. Think of it like adjusting the size of a vector so that it fits within a standard size of 1.\n",
    "\n",
    "The formula for Normalization looks like this:\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![](../images/normalization.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "Where:\n",
    "\n",
    "- $X_i$ is each individual value.\n",
    "- $\\|X\\|$ represents the Euclidean norm (or length) of the vector $X$.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "decee2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>MSSubClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.007100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.002083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.005333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.007330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.004208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LotArea  MSSubClass\n",
       "0  0.999975    0.007100\n",
       "1  0.999998    0.002083\n",
       "2  0.999986    0.005333\n",
       "3  0.999973    0.007330\n",
       "4  0.999991    0.004208"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scaler = Normalizer()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "\n",
    "scaled_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow_env)",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
